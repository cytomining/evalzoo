---
title: "Inspect metrics"
output: html_notebook
params:
  input_metrics_file_prefix: "results/4413769c/metrics"
  background_type: "non_rep"
  random_seed: 42
---

# Setup

```{r message=FALSE}
library(magrittr)
library(tidyverse)
library(glue)
library(arrow)
library(matric)
library(logger)
source("utils.R")
```


```{r}
set.seed(params$random_seed)
```


```{r}
knitr::opts_chunk$set(fig.height = 8, fig.width = 8, rows.print = 20)
```


```{r}
cat(yaml::as.yaml(params))
```

```{r}
type <- params$background_type
```

# Load metrics

```{r}
metric_set_names <- c(glue("level_1_0_{type}"), glue("level_1_{type}"))

metric_sets <-
  map(metric_set_names, function(metric_set) {
    parquet_file <-
      with(params, glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

    log_info("Reading {parquet_file} ...")

    arrow::read_parquet(glue(parquet_file))
  })

names(metric_sets) <- paste(metric_set_names, "metrics", sep = "_")

all_same_cols_rep <- attr(metric_sets[[1]], "all_same_cols_rep")
```

# Inspect metrics

## Functions

```{r}

color_map <- c(
  "reference" = "red",
  "pert" = "black"
)

plot_metric <-
  function(metrics,
           metric_name,
           plot_title,
           plot_subtitle) {

    metric_sym <- sym(metric_name)

    p <-
      metrics %>%
      mutate(point_order = as.numeric(factor(
        Metadata_reference_or_other,
        levels = c("reference", "pert"),
        ordered = TRUE
      ))) %>%
      arrange(desc(point_order)) %>%
      ggplot(aes(!!metric_sym,
        fill = Metadata_reference_or_other
      )) +
      geom_histogram(
        position = "identity",
        alpha = 0.5,
        bins = 50
      ) +
      scale_fill_manual(values = color_map) +
      ggtitle(plot_title, subtitle = plot_subtitle) +
      theme(legend.position = "bottom")

    list(fig1 = p)
  }
```


```{r}
#' Estimate statitics of the distribution of information retrieval metrics under the null hypothesis 
#'
#' @param m Number of positive examples (= number of replicates - 1)
#' @param n Number of negative examples (= number of controls, or number of non-replicates)
#' @param nn Number of simulations (default = 10000)
#'
#' @return statistics 
#'
retrieval_baseline <- function(m, n, nn = 10000, percentile = 0.90) {

  # average precision
  
  y_rank <- 1 - (seq(m + n) / (m + n))
  
  average_precision_null_samples <-
    map_dbl(seq(nn), function(i) {
      x <- as.factor(sample(c(rep(FALSE, n), rep(TRUE, m))))
      
      yardstick::average_precision_vec(x, y_rank, event_level = "second")
      
    })
  
  average_precision_stat <- quantile(average_precision_null_samples, c(percentile), names = FALSE)
  
  # R-precision

  k <- m
  
  r_precision_stat <-
    qhyper(p = percentile,
           m = m,
           n = n,
           k = k) / k
  
  data.frame(
    m = m, 
    n = n,
    sim_stat_average_precision_null = average_precision_stat,
    sim_stat_r_precision_null = r_precision_stat,
    sim_stat_average_precision_null_samples = average_precision_null_samples
  ) %>%
    nest(sim_stat_average_precision_null_samples = c(sim_stat_average_precision_null_samples))
  
}
retrieval_baseline(1, 1, 10)
```


```{r}
knitr::opts_chunk$set(fig.height = 6, fig.width = 6, rows.print = 20)
```

## Process metrics

### Level 1_0

```{r}
level_1_0_metrics <-
  metric_sets[[glue("level_1_0_{type}_metrics")]]
```


```{r}
cat(yaml::as.yaml(attr(level_1_0_metrics, "params")))
```


### Level 1

```{r}
level_1_metrics <-
  metric_sets[[glue("level_1_{type}_metrics")]]
```


```{r}
cat(yaml::as.yaml(attr(level_1_metrics, "params")))
```


## Compute null thresholds



```{r}
level_1_0_metrics %>%
  distinct(across(all_of(c(
    glue("sim_stat_signal_n_{type}_i"),
    glue("sim_stat_background_n_{type}_i")
  ))))
```
```{r}
pow <- 1.3
points <- level_1_0_metrics[[glue("sim_stat_background_n_{type}_i")]]
max_value <- max(points)
break_point <- ceiling(seq(1, ceiling((max_value)^(1/pow)), 1)**(pow))
points_mapped <- points %>% map_dbl(function(i) break_point[min(which(break_point > i))])

level_1_0_metrics <-
  level_1_0_metrics %>%
  mutate(sim_stat_background_n_mapped = points_mapped)
```


```{r}
level_1_0_metrics %>%
  distinct(across(all_of(c(
    glue("sim_stat_signal_n_{type}_i"),
    "sim_stat_background_n_mapped"
    #glue("sim_stat_background_n_{type}_i")
  ))))
```


```{r}
future::plan(future::multisession, workers = 14)
```

```{r}
null_thresholds <-
  level_1_0_metrics %>%
  distinct(across(all_of(c(
    glue("sim_stat_signal_n_{type}_i"),
    "sim_stat_background_n_mapped"
    #glue("sim_stat_background_n_{type}_i")
  )))) %>%
  rename(m = 1, n = 2) %>%
  furrr::future_pmap_dfr(function(m, n)
  {
    log_info("Compute retrieval random baseline for m = {m}, n = {n}")
    retrieval_baseline(m = m, n = n, nn = 10000)
  },
  .options = furrr::furrr_options(seed = params$random_seed))

null_thresholds %>% 
  select(-sim_stat_average_precision_null_samples) %>%
  arrange(m, n)
```


```{r}
join_vars <- c("m", "n")
names(join_vars) <-
  c(glue("sim_stat_signal_n_{type}_i"),
    "sim_stat_background_n_mapped")
join_vars
```


```{r}
level_1_0_metrics <-
  level_1_0_metrics %>%
  inner_join(null_thresholds,
             by = join_vars)
```

## Compute p-values and adjust metrics

### Level 1_0

```{r}
sim_retrieval_average_precision_type_i_nlog10pvalue <-
  glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue")

sim_retrieval_average_precision_type_i <-
  glue("sim_retrieval_average_precision_{type}_i")


sim_retrieval_average_precision_type_i_adjusted <-
  glue("sim_retrieval_average_precision_{type}_i_adjusted")

sim_retrieval_r_precision_type_i_adjusted <-
  glue("sim_retrieval_r_precision_{type}_i_adjusted")


level_1_0_metrics_null_adjusted <-
  level_1_0_metrics %>%
  rowwise() %>%
  mutate("{sim_retrieval_average_precision_type_i_nlog10pvalue}" :=
           -log10((
             1 + sum(
               sim_stat_average_precision_null_samples$sim_stat_average_precision_null_samples >
                 .data[[sim_retrieval_average_precision_type_i]]
             )
           ) /
             (
               1 + nrow(sim_stat_average_precision_null_samples)
             ))) %>%
  ungroup() %>%
  select(-sim_stat_average_precision_null_samples) %>%
  mutate(
    "{sim_retrieval_average_precision_type_i_adjusted}" :=
      .data[[glue("sim_retrieval_average_precision_{type}_i")]] - sim_stat_average_precision_null,
    "{sim_retrieval_r_precision_type_i_adjusted}" :=
      .data[[glue("sim_retrieval_r_precision_{type}_i")]] - sim_stat_r_precision_null
  )
```

## Aggregate metrics

### Level 1

```{r}
summary_cols <- attr(level_1_0_metrics, "all_same_cols_rep")

annotation_cols <- attr(level_1_0_metrics, "params")$calculate_index$sim_params$annotation_cols

annotation_cols_full <- unique(c(summary_cols, annotation_cols))

metadata <-
  level_1_0_metrics %>%
  dplyr::distinct(across(all_of(annotation_cols_full)))
```


```{r}
level_1_metrics_null_adjusted <- 
  level_1_0_metrics_null_adjusted %>%
  ungroup() %>%
  group_by(dplyr::across(dplyr::all_of(summary_cols))) %>%
  summarise(across(starts_with("sim_"),
                   list(mean_i = mean, median_i = median)),
            .groups = "keep") %>%
  dplyr::inner_join(metadata, by = summary_cols) %>%
  dplyr::select(all_of(annotation_cols_full), dplyr::everything()) %>%
  ungroup()
```


```{r}
stopifnot(
  compare::compare(
    level_1_metrics_null_adjusted %>%
      select(all_of(names(level_1_metrics))),
    level_1_metrics,
    ignoreAttrs = TRUE
  )$result
)
```


```{r}
metric_set <- glue("level_1_{type}_null_adjusted")

parquet_file <-
  with(params,
       glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

log_info("Writing {parquet_file} ...")

level_1_metrics_null_adjusted %>%
  arrow::write_parquet(glue(parquet_file))
```

## Plot metrics

### Level 1

```{r}
result <-
  plot_metric(
    level_1_metrics_null_adjusted,
    glue("sim_retrieval_average_precision_{type}_i_adjusted_mean_i"),
    glue("level_1_{type}"),
    attr(level_1_metrics, "metric_metadata")$method
  )
result$fig1
```


```{r}
level_1_metrics_null_adjusted %>%
  mutate(above_threshold =
           .data[[glue("sim_retrieval_average_precision_{type}_i_adjusted_mean_i")]] > 0) %>%
  count(above_threshold)
```
```{r}
level_1_metrics_null_adjusted %>%
  mutate(above_threshold =
           .data[[glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i")]] > -log10(0.10)) %>%
  count(above_threshold)
```

```{r}
level_1_0_metrics_null_adjusted %>%
  mutate(above_threshold =
           (.data[[glue("sim_retrieval_average_precision_{type}_i_adjusted")]] > 0) &
           (.data[[glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue")]] > -log10(0.10))) %>%
  ggplot(aes_string(
    glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue"),
    glue("sim_retrieval_average_precision_{type}_i_adjusted"),
    color = "above_threshold"
  )) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = -log10(0.10)) +
  theme_bw()
```

```{r}
result <-
  plot_metric(
    level_1_metrics_null_adjusted,
    glue("sim_retrieval_r_precision_{type}_i_adjusted_mean_i"),
    glue("level_1_{type}"),
    attr(level_1_metrics, "metric_metadata")$method
  )
result$fig1
```
```{r}
sim_retrieval_average_precision_type_i_nlog10qvalue_mean_i <-
  glue("sim_retrieval_average_precision_{type}_i_nlog10qvalue_mean_i")

sim_retrieval_average_precision_type_i_nlog10pvalue_mean_i <-
  glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i")

level_1_metrics_null_adjusted <-
  level_1_metrics_null_adjusted %>%
  mutate(
    "{sim_retrieval_average_precision_type_i_nlog10qvalue_mean_i}" := 
      -log10(p.adjust(10**-.data[[sim_retrieval_average_precision_type_i_nlog10pvalue_mean_i]], 
                      method = "BH")
             )
  )
```


```{r}
level_1_metrics_null_adjusted %>%
  ggplot(aes_string(
    glue("sim_retrieval_average_precision_{type}_i_mean_i"), 
    glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i"))) +
  geom_point() +
  geom_hline(yintercept = -log10(0.05)) +
  theme_bw()
```

```{r}
p <-
  level_1_metrics_null_adjusted %>%
  ggplot(aes_string(
    glue("sim_retrieval_average_precision_{type}_i_mean_i"),
    glue(
      "sim_retrieval_average_precision_{type}_i_nlog10qvalue_mean_i"
    )
  )) +
  geom_point(aes(
    text = names(level_1_0_metrics_null_adjusted) %>% str_subset("Metadata") %>% map_chr(function(x)
      sprintf("{%s}", x)) %>% paste(collapse = ":") %>% glue()
  )) +
  geom_hline(yintercept = -log10(0.05)) +
  theme_bw()

p


```


```{r}
l <- plotly::ggplotly(p)

htmlwidgets::saveWidget(l, with(params, glue("{input_metrics_file_prefix}_plot_1.html")))
```

```{r}
level_1_metrics_null_adjusted %>%
  mutate(above_threshold =
           .data[[glue("sim_retrieval_r_precision_{type}_i_adjusted_mean_i")]] > 0) %>%
  count(above_threshold)
```


```{r}
result <-
  plot_metric(
    level_1_metrics,
    "sim_mean_i_mean_i",
    "level_1",
    attr(level_1_metrics, "metric_metadata")$method
  )
result$fig1
```


```{r}
result <-
  plot_metric(
    level_1_metrics,
    glue("sim_scaled_mean_{type}_i_mean_i"),
    glue("level_1_{type}"),
    attr(level_1_metrics, "metric_metadata")$method
  )
result$fig1
```


```{r}
level_1_metrics %>%
  arrange(across(everything())) %>%
  head()
```


```{r}
level_1_metrics %>%
  select(all_of(c(
    glue("sim_retrieval_average_precision_{type}_i_mean_i"),
    glue("sim_retrieval_r_precision_{type}_i_mean_i"),
    glue("sim_ranked_relrank_mean_{type}_i_mean_i"),
    glue("sim_scaled_mean_{type}_i_mean_i")
  ))) %>%
  rename_with( ~ str_remove_all(., glue("sim_|_{type}_i_mean_i")), matches("sim_")) %>%
  GGally::ggpairs(progress = FALSE)
```
# Checks

```{r}
profiles <-
  arrow::read_parquet(attributes(level_1_0_metrics)$params$calculate_metrics$input_profile_file)
```

```{r}
metrics_counts <-
  level_1_metrics_null_adjusted %>% 
  count(across(all_of(c(glue("sim_stat_signal_n_{type}_i_mean_i"))))) %>%
  mutate(n_perts = .data[[glue("sim_stat_signal_n_{type}_i_mean_i")]] + 1) %>% 
  select(n_perts, n_groups = n) %>% 
  arrange(n_perts)

metrics_counts
```


```{r}
if(!is.null(attributes(level_1_0_metrics)$params$prepare_data$split_rows_on_column)) {
  split_col <-
    str_c(
      attributes(level_1_0_metrics)$params$prepare_data$split_rows_on_column,
      "_split"
    )
  
  profiles_counts <-
    profiles %>%
    filter(Metadata_reference_or_other != "reference") %>%
    count(across(all_of(c(split_col))), name = "n_perts") %>%
    count(n_perts, name = "n_groups") %>%
    filter(n_perts > 1) %>%
    arrange(n_perts)
  
  stopifnot(compare::compare(metrics_counts, profiles_counts, ignoreAttrs = TRUE)$result)
}
```

