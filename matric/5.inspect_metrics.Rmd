---
title: "Inspect metrics"
output: html_notebook
params:
  input_metrics_file_prefix: "results/de99e898/metrics"
  background_type: "non_rep"
---

# Setup

```{r message=FALSE}
library(magrittr)
library(tidyverse)
library(glue)
library(arrow)
library(matric)
library(logger)
source("utils.R")
```


```{r}
type <- params$background_type
```

# Functions

```{r}
plot_metric <-
  function(metrics,
           metric_name,
           plot_title,
           plot_subtitle) {
    color_map <- c("reference" = "red",
                   "pert" = "black")
    
    
    metric_sym <- sym(metric_name)
    
    p <-
      metrics %>%
      mutate(point_order = as.numeric(
        factor(
          Metadata_reference_or_other,
          levels = c("reference", "pert"),
          ordered = TRUE
        )
      )) %>%
      arrange(desc(point_order)) %>%
      ggplot(aes(!!metric_sym,
                 fill = Metadata_reference_or_other)) +
      geom_histogram(position = "identity",
                     alpha = 0.5,
                     bins = 50) +
      scale_fill_manual(values = color_map) +
      ggtitle(plot_title, subtitle = plot_subtitle) +
      theme(legend.position = "bottom") +
      theme_bw()
    
    list(fig1 = p)
  }
```

# Read

```{r}
metric_set <- glue("level_1_0_{type}_null_adjusted")

parquet_file <-
  with(params,
       glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

log_info("Reading {parquet_file} ...")

level_1_0_metrics_null_adjusted <-
  arrow::read_parquet(glue(parquet_file))
```


```{r}
metric_set <- glue("level_1_{type}_null_adjusted")

parquet_file <-
  with(params,
       glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

log_info("Reading {parquet_file} ...")

level_1_metrics_null_adjusted <-
  arrow::read_parquet(glue(parquet_file))
```

```{r}
significance_threshold <- 
  attr(level_1_0_metrics_null_adjusted, "significance_threshold")
```

# Plot metrics

## Average Precision

### Level 1

```{r}
result <-
  plot_metric(
    level_1_metrics_null_adjusted,
    glue("sim_retrieval_average_precision_{type}_i_adjusted_mean_i"),
    glue("level_1_{type}"),
    attr(level_1_metrics_null_adjusted, "metric_metadata")$method
  )
result$fig1
```

#### Compare p-value threshold and adjusted metric

```{r}
level_1_metrics_null_adjusted %>%
  mutate(above_threshold_adjusted_mean =
           (.data[[glue("sim_retrieval_average_precision_{type}_i_adjusted_mean_i")]] > 0)) %>%
  mutate(above_threshold_nlog10pvalue =
           (.data[[glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i")]] > -log10(significance_threshold))) %>%
  ggplot(aes_string(
    glue(
      "sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i"
    ),
    glue("sim_retrieval_average_precision_{type}_i_adjusted_mean_i")
  )) +
  geom_point(aes(color = interaction(above_threshold_adjusted_mean, above_threshold_nlog10pvalue))) +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = -log10(significance_threshold)) +
  guides(color = guide_legend(title = "Above threshold:\nadjusted_mean.pvalue")) +
  theme_bw()
```


```{r}
level_1_metrics_null_adjusted %>%
  mutate(above_threshold =
           .data[[glue("sim_retrieval_average_precision_{type}_i_adjusted_mean_i")]] > 0) %>%
  count(above_threshold)
```

Thresholding based on average p-value will give similar but not identical results

```{r}
level_1_metrics_null_adjusted %>%
  mutate(above_threshold =
           .data[[glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i")]] > -log10(significance_threshold)) %>%
  count(above_threshold)
```
Thresholding based on FDR-adjusted p-value 

```{r}
level_1_metrics_null_adjusted %>%
  mutate(above_threshold =
           .data[[glue("sim_retrieval_average_precision_{type}_i_nlog10qvalue_mean_i")]] > -log10(significance_threshold)) %>%
  count(above_threshold)
```

#### Statistic vs p-value

```{r}
p <- 
  level_1_metrics_null_adjusted %>%
  ggplot(aes_string(
    glue("sim_retrieval_average_precision_{type}_i_mean_i"), 
    glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i"))) +
  geom_jitter(height = 0.1, width = 0.05, alpha = 0.1, color = "red") +
  geom_point(aes(
    text = names(level_1_0_metrics_null_adjusted) %>% str_subset("Metadata") %>% map_chr(function(x)
      sprintf("{%s}", x)) %>% paste(collapse = ":") %>% glue()
  )) +
  geom_hline(yintercept = -log10(significance_threshold)) +
  theme_bw() + 
  labs(caption = "Jittered version of the points are in red")

p
```

```{r}
l <- plotly::ggplotly(p)

htmlwidgets::saveWidget(l, with(params, glue("{input_metrics_file_prefix}_plot_level_1_pvalue.html")))
```


```{r}
p <-
  level_1_metrics_null_adjusted %>%
  ggplot(aes_string(
    glue("sim_retrieval_average_precision_{type}_i_mean_i"),
    glue(
      "sim_retrieval_average_precision_{type}_i_nlog10qvalue_mean_i"
    )
  )) +
  geom_point(aes(
    text = names(level_1_metrics_null_adjusted) %>% str_subset("Metadata") %>% map_chr(function(x)
      sprintf("{%s}", x)) %>% paste(collapse = ":") %>% glue()
  )) +
  geom_jitter(height = 0.1, width = 0.05, alpha = 0.1, color = "red") +
  geom_hline(yintercept = -log10(significance_threshold)) +
  theme_bw() + 
  labs(caption = "Jittered version of the points are in red")

p
```


```{r}
l <- plotly::ggplotly(p)

htmlwidgets::saveWidget(l, with(params, glue("{input_metrics_file_prefix}_plot_level_1_qvalue.html")))
```

### Level 1_0


```{r}
result <-
  plot_metric(
    level_1_0_metrics_null_adjusted,
    glue("sim_retrieval_average_precision_{type}_i_adjusted"),
    glue("level_1_0_{type}"),
    attr(level_1_metrics_null_adjusted, "metric_metadata")$method
  )
result$fig1
```

#### Compare p-value threshold and adjusted metric

```{r}
level_1_0_metrics_null_adjusted %>%
  mutate(above_threshold_adjusted_mean =
           (.data[[glue("sim_retrieval_average_precision_{type}_i_adjusted")]] > 0)) %>%
  mutate(above_threshold_nlog10pvalue =
           (.data[[glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue")]] > -log10(significance_threshold))) %>%
  ggplot(aes_string(
    glue(
      "sim_retrieval_average_precision_{type}_i_nlog10pvalue"
    ),
    glue("sim_retrieval_average_precision_{type}_i_adjusted")
  )) +
  geom_point(aes(color = interaction(above_threshold_adjusted_mean, above_threshold_nlog10pvalue))) +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = -log10(significance_threshold)) +
  guides(color = guide_legend(title = "Above threshold:\nadjusted_mean.pvalue")) +
  theme_bw()
```
```{r}
level_1_0_metrics_null_adjusted %>%
  mutate(above_threshold =
           .data[[glue("sim_retrieval_average_precision_{type}_i_adjusted")]] > 0) %>%
  count(above_threshold)
```

## R-precision

### Level 1

```{r}
result <-
  plot_metric(
    level_1_metrics_null_adjusted,
    glue("sim_retrieval_r_precision_{type}_i_adjusted_mean_i"),
    glue("level_1_{type}"),
    attr(level_1_metrics_null_adjusted, "metric_metadata")$method
  )
result$fig1
```


```{r}
level_1_metrics_null_adjusted %>%
  mutate(above_threshold =
           .data[[glue("sim_retrieval_r_precision_{type}_i_adjusted_mean_i")]] > 0) %>%
  count(above_threshold)
```

## Other metrics

### Mean pairwise similarity

```{r}
result <-
  plot_metric(
    level_1_metrics_null_adjusted,
    "sim_mean_i_mean_i",
    "level_1",
    attr(level_1_metrics_null_adjusted, "metric_metadata")$method
  )
result$fig1
```

### Grit

```{r}
result <-
  plot_metric(
    level_1_metrics_null_adjusted,
    glue("sim_scaled_mean_{type}_i_mean_i"),
    glue("level_1_{type}"),
    attr(level_1_metrics_null_adjusted, "metric_metadata")$method
  )
result$fig1
```

### Pairwise scatter plots

```{r}
level_1_metrics_null_adjusted %>%
  select(all_of(c(
    glue("sim_retrieval_average_precision_{type}_i_mean_i"),
    glue("sim_retrieval_r_precision_{type}_i_mean_i"),
    glue("sim_ranked_relrank_mean_{type}_i_mean_i"),
    glue("sim_scaled_mean_{type}_i_mean_i")
  ))) %>%
  rename_with( ~ str_remove_all(., glue("sim_|_{type}_i_mean_i")), matches("sim_")) %>%
  GGally::ggpairs(progress = FALSE) +
  theme_bw()
```


