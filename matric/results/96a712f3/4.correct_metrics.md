Compute metric significance
================

- <a href="#setup" id="toc-setup">1 Setup</a>
- <a href="#load-metrics" id="toc-load-metrics">2 Load metrics</a>
- <a href="#process-metrics" id="toc-process-metrics">3 Process
  metrics</a>
  - <a href="#level-1_0" id="toc-level-1_0">3.1 Level 1_0</a>
  - <a href="#level-1" id="toc-level-1">3.2 Level 1</a>
  - <a href="#compute-null-thresholds" id="toc-compute-null-thresholds">3.3
    Compute null thresholds</a>
  - <a href="#compute-p-values-and-adjust-metrics"
    id="toc-compute-p-values-and-adjust-metrics">3.4 Compute p-values and
    adjust metrics</a>
    - <a href="#level-1_0-1" id="toc-level-1_0-1">3.4.1 Level 1_0</a>
  - <a href="#aggregate-metrics" id="toc-aggregate-metrics">3.5 Aggregate
    metrics</a>
    - <a href="#level-1-1" id="toc-level-1-1">3.5.1 Level 1</a>
- <a href="#correct-for-multiple-testing"
  id="toc-correct-for-multiple-testing">4 Correct for multiple testing</a>
  - <a href="#level-1_0-2" id="toc-level-1_0-2">4.1 Level 1_0</a>
  - <a href="#level-1-2" id="toc-level-1-2">4.2 Level 1</a>
- <a href="#write" id="toc-write">5 Write</a>
- <a href="#checks" id="toc-checks">6 Checks</a>

# 1 Setup

``` r
library(magrittr)
library(tidyverse)
library(glue)
library(arrow)
library(matric)
library(logger)
source("utils.R")
source("retrieval_baseline.R")
```

``` r
set.seed(params$random_seed)
```

``` r
future::plan(future::multisession, workers = 14)
```

``` r
knitr::opts_chunk$set(fig.height = 8, fig.width = 8, rows.print = 20)
```

``` r
cat(yaml::as.yaml(params))
```

    ## input_metrics_file_prefix: results/96a712f3/metrics
    ## background_type: ref
    ## random_seed: 42
    ## significance_threshold: 0.05

``` r
type <- params$background_type
```

# 2 Load metrics

``` r
metric_set_names <- c(glue("level_1_0_{type}"), glue("level_1_{type}"))

metric_sets <-
  map(metric_set_names, function(metric_set) {
    parquet_file <-
      with(params, glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

    log_info("Reading {parquet_file} ...")

    arrow::read_parquet(glue(parquet_file))
  })

names(metric_sets) <- paste(metric_set_names, "metrics", sep = "_")

all_same_cols_rep <- attr(metric_sets[[1]], "all_same_cols_rep")
```

# 3 Process metrics

## 3.1 Level 1_0

``` r
level_1_0_metrics <-
  metric_sets[[glue("level_1_0_{type}_metrics")]]
```

``` r
cat(yaml::as.yaml(attr(level_1_0_metrics, "params")))
```

    ## prepare_data:
    ##   input_profile_files:
    ##   - tag: ''
    ##     filename: /Users/shsingh/work/projects/2019_07_11_JUMP-CP/workspace/software/pilot-cpjump1-data/collated/2020_11_04_CPJUMP1/2020_11_04_CPJUMP1_U2OS_48_Compound_Standard_normalized_feature_select_negcon.parquet
    ##   output_profile_file: results/96a712f3/profiles.parquet
    ##   data_path: /Users/shsingh/work/projects/2019_07_11_JUMP-CP/workspace/software/pilot-cpjump1-data/collated/2020_11_04_CPJUMP1
    ##   reference_set:
    ##     Metadata_negcon_or_other: negcon
    ##   random_seed: 42
    ##   external_metadata: ~
    ##   subsample_fraction: 1
    ##   subsample_pert_strata: ~
    ##   subsample_reference_strata: ~
    ##   shuffle: no
    ##   shuffle_bad_groups_threshold: ~
    ##   shuffle_group: ~
    ##   shuffle_strata: ~
    ##   shuffle_exclude: ~
    ##   aggregate_by: ~
    ##   filter_by: ~
    ##   add_dummy_metadata_column: no
    ##   split_rows_on_column: ~
    ## calculate_index:
    ##   input_profile_file: results/96a712f3/profiles.parquet
    ##   output_index_file: results/96a712f3/index.parquet
    ##   output_collatedindex_file: results/96a712f3/collatedindex.parquet
    ##   sim_params:
    ##     reference:
    ##       Metadata_reference_or_other: reference
    ##     all_same_cols_ref:
    ##     - Metadata_cell_line
    ##     - Metadata_timepoint
    ##     - Metadata_experiment_type
    ##     - Metadata_experiment_condition
    ##     - Metadata_Plate
    ##     all_same_cols_rep:
    ##     - Metadata_cell_line
    ##     - Metadata_timepoint
    ##     - Metadata_experiment_type
    ##     - Metadata_experiment_condition
    ##     - Metadata_target
    ##     - Metadata_broad_sample
    ##     - Metadata_control_type
    ##     - Metadata_reference_or_other
    ##     all_same_cols_rep_ref: ~
    ##     any_different_cols_non_rep: ~
    ##     all_same_cols_non_rep: ~
    ##     all_different_cols_non_rep: ~
    ##     all_same_cols_group: ~
    ##     any_different_cols_group: ~
    ##     annotation_cols:
    ##     - Metadata_cell_line
    ##     - Metadata_timepoint
    ##     - Metadata_experiment_type
    ##     - Metadata_experiment_condition
    ##     - Metadata_target
    ##     - Metadata_broad_sample
    ##     - Metadata_control_type
    ##     - Metadata_reference_or_other
    ## calculate_metrics:
    ##   input_profile_file: results/96a712f3/profiles.parquet
    ##   input_collatedindex_file: results/96a712f3/collatedindex.parquet
    ##   output_collatedsim_file: results/96a712f3/collatedsim.parquet
    ##   output_metrics_file_prefix: results/96a712f3/metrics
    ##   similarity_method: cosine
    ##   parallel_workers: 8

## 3.2 Level 1

``` r
level_1_metrics <-
  metric_sets[[glue("level_1_{type}_metrics")]]
```

``` r
cat(yaml::as.yaml(attr(level_1_metrics, "params")))
```

    ## prepare_data:
    ##   input_profile_files:
    ##   - tag: ''
    ##     filename: /Users/shsingh/work/projects/2019_07_11_JUMP-CP/workspace/software/pilot-cpjump1-data/collated/2020_11_04_CPJUMP1/2020_11_04_CPJUMP1_U2OS_48_Compound_Standard_normalized_feature_select_negcon.parquet
    ##   output_profile_file: results/96a712f3/profiles.parquet
    ##   data_path: /Users/shsingh/work/projects/2019_07_11_JUMP-CP/workspace/software/pilot-cpjump1-data/collated/2020_11_04_CPJUMP1
    ##   reference_set:
    ##     Metadata_negcon_or_other: negcon
    ##   random_seed: 42
    ##   external_metadata: ~
    ##   subsample_fraction: 1
    ##   subsample_pert_strata: ~
    ##   subsample_reference_strata: ~
    ##   shuffle: no
    ##   shuffle_bad_groups_threshold: ~
    ##   shuffle_group: ~
    ##   shuffle_strata: ~
    ##   shuffle_exclude: ~
    ##   aggregate_by: ~
    ##   filter_by: ~
    ##   add_dummy_metadata_column: no
    ##   split_rows_on_column: ~
    ## calculate_index:
    ##   input_profile_file: results/96a712f3/profiles.parquet
    ##   output_index_file: results/96a712f3/index.parquet
    ##   output_collatedindex_file: results/96a712f3/collatedindex.parquet
    ##   sim_params:
    ##     reference:
    ##       Metadata_reference_or_other: reference
    ##     all_same_cols_ref:
    ##     - Metadata_cell_line
    ##     - Metadata_timepoint
    ##     - Metadata_experiment_type
    ##     - Metadata_experiment_condition
    ##     - Metadata_Plate
    ##     all_same_cols_rep:
    ##     - Metadata_cell_line
    ##     - Metadata_timepoint
    ##     - Metadata_experiment_type
    ##     - Metadata_experiment_condition
    ##     - Metadata_target
    ##     - Metadata_broad_sample
    ##     - Metadata_control_type
    ##     - Metadata_reference_or_other
    ##     all_same_cols_rep_ref: ~
    ##     any_different_cols_non_rep: ~
    ##     all_same_cols_non_rep: ~
    ##     all_different_cols_non_rep: ~
    ##     all_same_cols_group: ~
    ##     any_different_cols_group: ~
    ##     annotation_cols:
    ##     - Metadata_cell_line
    ##     - Metadata_timepoint
    ##     - Metadata_experiment_type
    ##     - Metadata_experiment_condition
    ##     - Metadata_target
    ##     - Metadata_broad_sample
    ##     - Metadata_control_type
    ##     - Metadata_reference_or_other
    ## calculate_metrics:
    ##   input_profile_file: results/96a712f3/profiles.parquet
    ##   input_collatedindex_file: results/96a712f3/collatedindex.parquet
    ##   output_collatedsim_file: results/96a712f3/collatedsim.parquet
    ##   output_metrics_file_prefix: results/96a712f3/metrics
    ##   similarity_method: cosine
    ##   parallel_workers: 8

## 3.3 Compute null thresholds

``` r
level_1_0_metrics %>%
  distinct(across(all_of(c(
    glue("sim_stat_signal_n_{type}_i"),
    glue("sim_stat_background_n_{type}_i")
  ))))
```

| sim_stat_signal_n\_ref_i | sim_stat_background_n\_ref_i |
|-------------------------:|-----------------------------:|
|                        3 |                           64 |
|                        7 |                           64 |

``` r
pow <- 1.3
points <- level_1_0_metrics[[glue("sim_stat_background_n_{type}_i")]]
max_value <- max(points)
break_point <- ceiling(seq(1, ceiling((max_value)^(1/pow)), 1)**(pow))
points_mapped <- points %>% map_dbl(function(i) break_point[min(which(break_point > i))])

level_1_0_metrics <-
  level_1_0_metrics %>%
  mutate(sim_stat_background_n_mapped = points_mapped)
```

``` r
level_1_0_metrics %>%
  distinct(across(all_of(
    c(
      glue("sim_stat_signal_n_{type}_i"),
      "sim_stat_background_n_mapped"
    )
  )))
```

| sim_stat_signal_n\_ref_i | sim_stat_background_n\_mapped |
|-------------------------:|------------------------------:|
|                        3 |                            66 |
|                        7 |                            66 |

``` r
null_thresholds <-
  level_1_0_metrics %>%
  distinct(across(all_of(
    c(
      glue("sim_stat_signal_n_{type}_i"),
      "sim_stat_background_n_mapped"
    )
  ))) %>%
  rename(m = 1, n = 2) %>%
  furrr::future_pmap_dfr(function(m, n)
  {
    log_info("Compute retrieval random baseline for m = {m}, n = {n}")
    retrieval_baseline(
      m = m,
      n = n,
      nn = 10000,
      percentile = 1 - params$significance_threshold
    )
  },
  .options = furrr::furrr_options(seed = params$random_seed))

null_thresholds %>%
  select(-sim_stat_average_precision_null_samples) %>%
  arrange(m, n)
```

|   m |   n | sim_stat_average_precision_null | sim_stat_r\_precision_null |
|----:|----:|--------------------------------:|---------------------------:|
|   3 |  66 |                       0.3102739 |                  0.3333333 |
|   7 |  66 |                       0.2788273 |                  0.2857143 |

``` r
join_vars <- c("m", "n")
names(join_vars) <-
  c(glue("sim_stat_signal_n_{type}_i"),
    "sim_stat_background_n_mapped")
join_vars
```

    ##      sim_stat_signal_n_ref_i sim_stat_background_n_mapped 
    ##                          "m"                          "n"

``` r
level_1_0_metrics <-
  level_1_0_metrics %>%
  inner_join(null_thresholds,
             by = join_vars)
```

## 3.4 Compute p-values and adjust metrics

### 3.4.1 Level 1_0

``` r
sim_retrieval_average_precision_type_i_nlog10pvalue <-
  glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue")

sim_retrieval_average_precision_type_i <-
  glue("sim_retrieval_average_precision_{type}_i")


sim_retrieval_average_precision_type_i_adjusted <-
  glue("sim_retrieval_average_precision_{type}_i_adjusted")

sim_retrieval_r_precision_type_i_adjusted <-
  glue("sim_retrieval_r_precision_{type}_i_adjusted")


level_1_0_metrics_null_adjusted <-
  level_1_0_metrics %>%
  rowwise() %>%
  mutate("{sim_retrieval_average_precision_type_i_nlog10pvalue}" :=
           -log10((
             1 + sum(
               sim_stat_average_precision_null_samples$sim_stat_average_precision_null_samples >
                 .data[[sim_retrieval_average_precision_type_i]]
             )
           ) /
             (
               1 + nrow(sim_stat_average_precision_null_samples)
             ))) %>%
  ungroup() %>%
  select(-sim_stat_average_precision_null_samples) %>%
  mutate(
    "{sim_retrieval_average_precision_type_i_adjusted}" :=
      .data[[glue("sim_retrieval_average_precision_{type}_i")]] - sim_stat_average_precision_null,
    "{sim_retrieval_r_precision_type_i_adjusted}" :=
      .data[[glue("sim_retrieval_r_precision_{type}_i")]] - sim_stat_r_precision_null
  )

c("all_same_cols_rep", "metric_metadata", "params") %>%
  walk(function(a) attr(level_1_0_metrics_null_adjusted, a) <<-
         attr(level_1_0_metrics, a))
```

## 3.5 Aggregate metrics

### 3.5.1 Level 1

``` r
summary_cols <- attr(level_1_0_metrics, "all_same_cols_rep")

annotation_cols <- attr(level_1_0_metrics, "params")$calculate_index$sim_params$annotation_cols

annotation_cols_full <- unique(c(summary_cols, annotation_cols))

metadata <-
  level_1_0_metrics %>%
  dplyr::distinct(across(all_of(annotation_cols_full)))
```

``` r
level_1_metrics_null_adjusted <- 
  level_1_0_metrics_null_adjusted %>%
  ungroup() %>%
  group_by(dplyr::across(dplyr::all_of(summary_cols))) %>%
  summarise(across(starts_with("sim_"),
                   list(mean_i = mean, median_i = median)),
            .groups = "keep") %>%
  dplyr::inner_join(metadata, by = summary_cols) %>%
  dplyr::select(all_of(annotation_cols_full), dplyr::everything()) %>%
  ungroup()

c("all_same_cols_rep", "metric_metadata", "params") %>%
  walk(function(a) attr(level_1_metrics_null_adjusted, a) <<-
         attr(level_1_metrics, a))
```

``` r
stopifnot(
  compare::compare(
    level_1_metrics_null_adjusted %>%
      select(all_of(names(level_1_metrics))),
    level_1_metrics,
    ignoreAttrs = TRUE
  )$result
)
```

# 4 Correct for multiple testing

## 4.1 Level 1_0

I’m not sure what’s the right way of correcting at Level 1_0, where
there are groups of highly correlated hypothesis (each set of replicates
is a correlated hypothesis set)

## 4.2 Level 1

``` r
sim_retrieval_average_precision_type_i_nlog10qvalue_mean_i <-
  glue("sim_retrieval_average_precision_{type}_i_nlog10qvalue_mean_i")

sim_retrieval_average_precision_type_i_nlog10pvalue_mean_i <-
  glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i")

level_1_metrics_null_adjusted <-
  level_1_metrics_null_adjusted %>%
  mutate(
    "{sim_retrieval_average_precision_type_i_nlog10qvalue_mean_i}" := 
      -log10(p.adjust(10**-.data[[sim_retrieval_average_precision_type_i_nlog10pvalue_mean_i]], 
                      method = "BH")
             )
  )
```

# 5 Write

``` r
metric_set <- glue("level_1_0_{type}_null_adjusted")

parquet_file <-
  with(params,
       glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

log_info("Writing {parquet_file} ...")

attr(level_1_0_metrics_null_adjusted, "significance_threshold") <- params$significance_threshold

level_1_0_metrics_null_adjusted %>%
  arrow::write_parquet(glue(parquet_file))
```

``` r
metric_set <- glue("level_1_{type}_null_adjusted")

parquet_file <-
  with(params,
       glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

log_info("Writing {parquet_file} ...")

level_1_metrics_null_adjusted %>%
  arrow::write_parquet(glue(parquet_file))
```

# 6 Checks

``` r
profiles <-
  arrow::read_parquet(attributes(level_1_0_metrics)$params$calculate_metrics$input_profile_file)
```

``` r
metrics_counts <-
  level_1_metrics_null_adjusted %>% 
  count(across(all_of(c(glue("sim_stat_signal_n_{type}_i_mean_i"))))) %>%
  mutate(n_perts = .data[[glue("sim_stat_signal_n_{type}_i_mean_i")]] + 1) %>% 
  select(n_perts, n_groups = n) %>% 
  arrange(n_perts)

metrics_counts
```

| n_perts | n_groups |
|--------:|---------:|
|       4 |      292 |
|       8 |       14 |

``` r
if(!is.null(attributes(level_1_0_metrics)$params$prepare_data$split_rows_on_column)) {
  split_col <-
    str_c(
      attributes(level_1_0_metrics)$params$prepare_data$split_rows_on_column,
      "_split"
    )
  
  profiles_counts <-
    profiles %>%
    filter(Metadata_reference_or_other != "reference") %>%
    count(across(all_of(c(split_col))), name = "n_perts") %>%
    count(n_perts, name = "n_groups") %>%
    filter(n_perts > 1) %>%
    arrange(n_perts)
  
  stopifnot(compare::compare(metrics_counts, profiles_counts, ignoreAttrs = TRUE)$result)
}
```
