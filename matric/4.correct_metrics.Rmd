---
title: "Compute metric significance"
output: html_notebook
params:
  input_metrics_file_prefix: "results/52185d5c/metrics"
  background_type: "ref"
  random_seed: 42
  significance_threshold: 0.05
---

# Setup

```{r message=FALSE}
library(magrittr)
library(tidyverse)
library(glue)
library(arrow)
library(matric)
library(logger)
source("utils.R")
source("retrieval_baseline.R")
```


```{r}
set.seed(params$random_seed)
```


```{r}
future::plan(future::multisession, workers = 14)
```


```{r}
knitr::opts_chunk$set(fig.height = 8, fig.width = 8, rows.print = 20)
```


```{r}
cat(yaml::as.yaml(params))
```


```{r}
type <- params$background_type
```

# Load metrics

```{r}
metric_set_names <- c(glue("level_1_0_{type}"), glue("level_1_{type}"))

metric_sets <-
  map(metric_set_names, function(metric_set) {
    parquet_file <-
      with(params, glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

    log_info("Reading {parquet_file} ...")

    arrow::read_parquet(glue(parquet_file))
  })

names(metric_sets) <- paste(metric_set_names, "metrics", sep = "_")

all_same_cols_rep <- attr(metric_sets[[1]], "all_same_cols_rep")
```


# Process metrics

## Level 1_0

```{r}
level_1_0_metrics <-
  metric_sets[[glue("level_1_0_{type}_metrics")]]
```


```{r}
cat(yaml::as.yaml(attr(level_1_0_metrics, "params")))
```

## Level 1

```{r}
level_1_metrics <-
  metric_sets[[glue("level_1_{type}_metrics")]]
```


```{r}
cat(yaml::as.yaml(attr(level_1_metrics, "params")))
```

## Compute null thresholds

```{r}
level_1_0_metrics %>%
  distinct(across(all_of(c(
    glue("sim_stat_signal_n_{type}_i"),
    glue("sim_stat_background_n_{type}_i")
  ))))
```


```{r}
pow <- 1.3
points <- level_1_0_metrics[[glue("sim_stat_background_n_{type}_i")]]
max_value <- max(points)
break_point <- ceiling(seq(1, ceiling((max_value)^(1/pow)), 1)**(pow))
points_mapped <- points %>% map_dbl(function(i) break_point[min(which(break_point > i))])

level_1_0_metrics <-
  level_1_0_metrics %>%
  mutate(sim_stat_background_n_mapped = points_mapped)
```


```{r}
level_1_0_metrics %>%
  distinct(across(all_of(
    c(
      glue("sim_stat_signal_n_{type}_i"),
      "sim_stat_background_n_mapped"
    )
  )))
```


```{r}
null_thresholds <-
  level_1_0_metrics %>%
  distinct(across(all_of(
    c(
      glue("sim_stat_signal_n_{type}_i"),
      "sim_stat_background_n_mapped"
    )
  ))) %>%
  rename(m = 1, n = 2) %>%
  furrr::future_pmap_dfr(function(m, n)
  {
    log_info("Compute retrieval random baseline for m = {m}, n = {n}")
    retrieval_baseline(
      m = m,
      n = n,
      nn = 10000,
      percentile = 1 - params$significance_threshold
    )
  },
  .options = furrr::furrr_options(seed = params$random_seed))

null_thresholds %>%
  select(-sim_stat_average_precision_null_samples) %>%
  arrange(m, n)
```


```{r}
join_vars <- c("m", "n")
names(join_vars) <-
  c(glue("sim_stat_signal_n_{type}_i"),
    "sim_stat_background_n_mapped")
join_vars
```


```{r}
level_1_0_metrics <-
  level_1_0_metrics %>%
  inner_join(null_thresholds,
             by = join_vars)
```

## Compute p-values and adjust metrics

### Level 1_0

```{r}
sim_retrieval_average_precision_type_i_nlog10pvalue <-
  glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue")

sim_retrieval_average_precision_type_i <-
  glue("sim_retrieval_average_precision_{type}_i")


sim_retrieval_average_precision_type_i_adjusted <-
  glue("sim_retrieval_average_precision_{type}_i_adjusted")

sim_retrieval_r_precision_type_i_adjusted <-
  glue("sim_retrieval_r_precision_{type}_i_adjusted")


level_1_0_metrics_null_adjusted <-
  level_1_0_metrics %>%
  rowwise() %>%
  mutate("{sim_retrieval_average_precision_type_i_nlog10pvalue}" :=
           -log10((
             1 + sum(
               sim_stat_average_precision_null_samples$sim_stat_average_precision_null_samples >
                 .data[[sim_retrieval_average_precision_type_i]]
             )
           ) /
             (
               1 + nrow(sim_stat_average_precision_null_samples)
             ))) %>%
  ungroup() %>%
  select(-sim_stat_average_precision_null_samples) %>%
  mutate(
    "{sim_retrieval_average_precision_type_i_adjusted}" :=
      .data[[glue("sim_retrieval_average_precision_{type}_i")]] - sim_stat_average_precision_null,
    "{sim_retrieval_r_precision_type_i_adjusted}" :=
      .data[[glue("sim_retrieval_r_precision_{type}_i")]] - sim_stat_r_precision_null
  )

c("all_same_cols_rep", "metric_metadata", "params") %>%
  walk(function(a) attr(level_1_0_metrics_null_adjusted, a) <<-
         attr(level_1_0_metrics, a))
```


## Aggregate metrics

### Level 1

```{r}
summary_cols <- attr(level_1_0_metrics, "all_same_cols_rep")

annotation_cols <- attr(level_1_0_metrics, "params")$calculate_index$sim_params$annotation_cols

annotation_cols_full <- unique(c(summary_cols, annotation_cols))

metadata <-
  level_1_0_metrics %>%
  dplyr::distinct(across(all_of(annotation_cols_full)))
```


```{r}
level_1_metrics_null_adjusted <- 
  level_1_0_metrics_null_adjusted %>%
  ungroup() %>%
  group_by(dplyr::across(dplyr::all_of(summary_cols))) %>%
  summarise(across(starts_with("sim_"),
                   list(mean_i = mean, median_i = median)),
            .groups = "keep") %>%
  dplyr::inner_join(metadata, by = summary_cols) %>%
  dplyr::select(all_of(annotation_cols_full), dplyr::everything()) %>%
  ungroup()

c("all_same_cols_rep", "metric_metadata", "params") %>%
  walk(function(a) attr(level_1_metrics_null_adjusted, a) <<-
         attr(level_1_metrics, a))
```


```{r}
stopifnot(
  compare::compare(
    level_1_metrics_null_adjusted %>%
      select(all_of(names(level_1_metrics))),
    level_1_metrics,
    ignoreAttrs = TRUE
  )$result
)
```

# Correct for multiple testing

## Level 1_0

I'm not sure what's the right way of correcting at Level 1_0, where there are groups of highly correlated hypothesis (each set of replicates is a correlated hypothesis set)

## Level 1

```{r}
sim_retrieval_average_precision_type_i_nlog10qvalue_mean_i <-
  glue("sim_retrieval_average_precision_{type}_i_nlog10qvalue_mean_i")

sim_retrieval_average_precision_type_i_nlog10pvalue_mean_i <-
  glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i")

level_1_metrics_null_adjusted <-
  level_1_metrics_null_adjusted %>%
  mutate(
    "{sim_retrieval_average_precision_type_i_nlog10qvalue_mean_i}" := 
      -log10(p.adjust(10**-.data[[sim_retrieval_average_precision_type_i_nlog10pvalue_mean_i]], 
                      method = "BH")
             )
  )
```


# Write

```{r}
metric_set <- glue("level_1_0_{type}_null_adjusted")

parquet_file <-
  with(params,
       glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

log_info("Writing {parquet_file} ...")

attr(level_1_0_metrics_null_adjusted, "significance_threshold") <- params$significance_threshold

level_1_0_metrics_null_adjusted %>%
  arrow::write_parquet(glue(parquet_file))
```


```{r}
metric_set <- glue("level_1_{type}_null_adjusted")

parquet_file <-
  with(params,
       glue("{input_metrics_file_prefix}_{metric_set}.parquet"))

log_info("Writing {parquet_file} ...")

level_1_metrics_null_adjusted %>%
  arrow::write_parquet(glue(parquet_file))
```

# Checks


```{r}
profiles <-
  arrow::read_parquet(attributes(level_1_0_metrics)$params$calculate_metrics$input_profile_file)
```

```{r}
metrics_counts <-
  level_1_metrics_null_adjusted %>% 
  count(across(all_of(c(glue("sim_stat_signal_n_{type}_i_mean_i"))))) %>%
  mutate(n_perts = .data[[glue("sim_stat_signal_n_{type}_i_mean_i")]] + 1) %>% 
  select(n_perts, n_groups = n) %>% 
  arrange(n_perts)

metrics_counts
```


```{r}
if(!is.null(attributes(level_1_0_metrics)$params$prepare_data$split_rows_on_column)) {
  split_col <-
    str_c(
      attributes(level_1_0_metrics)$params$prepare_data$split_rows_on_column,
      "_split"
    )
  
  profiles_counts <-
    profiles %>%
    filter(Metadata_reference_or_other != "reference") %>%
    count(across(all_of(c(split_col))), name = "n_perts") %>%
    count(n_perts, name = "n_groups") %>%
    filter(n_perts > 1) %>%
    arrange(n_perts)
  
  stopifnot(compare::compare(metrics_counts, profiles_counts, ignoreAttrs = TRUE)$result)
}
```

